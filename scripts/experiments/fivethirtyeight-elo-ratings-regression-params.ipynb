{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f0052cd0-ba57-49b1-a137-2087676e87f3","_uuid":"8798c611cfbc65cbe329aa185e76b5a9471a53f1"},"source":["# Regression Hyperparameter Optimization"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":true},"outputs":[],"source":["# importing necessary packages\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import log_loss"]},{"cell_type":"markdown","metadata":{"_cell_guid":"5569a2a0-cd31-4045-a060-9777417fc80f","_uuid":"3b851dbc3778b1d8443707eb90e1a34fb54b8f79"},"source":["There are a handful of different parameters and different ways with which to build these elo ratings.\n","- K: the learning rate\n","- HOME_ADVANTAGE: how much of a home court advantage each team receives\n","- CONF_REGRESRSION_FACTOR: how much a team's elo rating is regressed to their conference's mean elo\n","- D1_REGRESSION_FACTOR: how much a team's elo rating is regressed to the NCAA mean elo (which will always be 1500)\n","- CONF_TOURNAMENT (bool): whether team's elo rating should be updated during their conference tournament\n","- NCAA_TOURNAMENT (bool): whether a team's elo rating should be updated during any NCAA tournament games\n","- OTHER_TOURNAMENT (bool): whether a team's elo rating should be updated during other postseason tournaments (NIT, CBI)\n","- EVAL_MODE: how to evaluate a model (currently using log-loss)\n","- EVAL_GAMES: which games are considered in evaluating the model\n","\n","Theoretically, each of these parameters/options should be considered together, but I can treat most of them as independent and optimize them seperately. There are a few parameters which I can't treat as independent.\n","\n","- CONF_REGRESSION_FACTOR and D1_REGRESSION_FACTOR need to be considered together because they're dependent on each other. They both must be in the range [0,1], but their sum also has to be less than or equal to 1. Intuitively, the larger one is, the smaller the other is.\n","- K should also be considered with the reversion factors. Intuitively, these might correlate; how well we can regress each team's elo to their true rating affects how quickly we want our elo ratings to update.\n","- EVAL_GAMES will also effect how the other parameters should be set, but EVAL_GAMES should be set based on which games I want to use elo rating's to predict. For now, I'll evaluate all games; I want this model to predict who wins each game, not just postseason games.\n","- EVAL_MODE isn't something I want to optimize; that's a good way to emulate overfitting.\n","\n","HOME_ADVANTAGE and the TOURNAMENT parameters shouldn't really affect the other parameters. Thus, I'm going to only optimize three parameters here: K, CONF_REGRESSION_FACTOR, and D1_REGRESSION_FACTOR. "]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"0c7a3dd7-72b3-434a-947f-d9fca0fbc5ae","_uuid":"542133a36b3b2418a59093e9f79a2ec59f1ef4b1","collapsed":true,"trusted":true},"outputs":[],"source":["# Setting constant parameters\n","DATA_PATH = \"../../march-machine-learning-mania-2024-data\"\n","HOME_ADVANTAGE = 100.\n","\n","# Creating list of tuples being considered\n","PARAM_TUPLES = [] # Consists of tuples (K, CONF_REGRESSION_FACTOR, D1_REGRESSION_FACTOR, LOSS)\n","for i in range(32,64,4):\n","    for j in range(0,12,1):\n","        for k in range(0,12-j,1):\n","            PARAM_TUPLES.append( [i,j/20.,k/20., -1] )"]},{"cell_type":"markdown","metadata":{},"source":["This creates all combinations of parameters such that:\n","- K is in range [32,60] and is a multiple of 4\n","- CONF_REGRESSION_PARAMETER is in range [0,0.55] and is a multiple of 0.05\n","- D1_REGRESSION_PARAMETER is in range [0,0.55] and is a multiple of 0.05\n","- CONF_REGRESSION_PARAMETER + D1_REGRESSION_PARAMETER is in range [0,0.55]\n","\n","For each set of these possible tuples, I'm going to run the elo ratings on the entire set of data, calculate the mean log loss, and store it in the tuple. When this is complete, I will look for the set of hyperparameters which will minimize the (negative) log loss. I expect that, if this sampling of tuples were plotted, we should get a relatively smooth curve."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# HELPER FUNCTIONS\n","def elo_pred(elo1, elo2):\n","    return(1. / (10. ** (-(elo1 - elo2) / 400.) + 1.))\n","\n","def expected_margin(elo_diff):\n","    return((7.5 + 0.006 * elo_diff))\n","\n","def elo_update(w_elo, l_elo, margin, K):\n","    elo_diff = w_elo - l_elo\n","    pred = elo_pred(w_elo, l_elo)\n","    mult = ((margin + 3.) ** 0.8) / expected_margin(elo_diff)\n","    update = K * mult * (1 - pred)\n","    return(pred, update)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Completed iteration 50\n","Completed iteration 100\n","Completed iteration 150\n","Completed iteration 200\n","Completed iteration 250\n","Completed iteration 300\n","Completed iteration 350\n","Completed iteration 400\n","Completed iteration 450\n","Completed iteration 500\n","Completed iteration 550\n","Completed iteration 600\n"]}],"source":["for index in range(len(PARAM_TUPLES)):\n","    PARAM_TUPLE = PARAM_TUPLES[index]\n","    K = PARAM_TUPLE[0]\n","    CONF_REGRESSION_FACTOR = PARAM_TUPLE[1]\n","    D1_REGRESSION_FACTOR = PARAM_TUPLE[2]\n","\n","    rs = pd.read_csv(DATA_PATH + \"/MRegularSeasonCompactResults.csv\")\n","    team_ids = set(rs.WTeamID).union(set(rs.LTeamID))\n","\n","    # Creating dict of conference affiliation by year\n","    conf_df = pd.read_csv(DATA_PATH + \"/MTeamConferences.csv\")\n","    conf_df['TeamYear'] = conf_df.Season.astype(str) + \"_\" + conf_df.TeamID.astype(str)\n","    conf_dict = dict(zip(conf_df['TeamYear'], conf_df['ConfAbbrev']))\n","    confs = set(conf_df['ConfAbbrev'])\n","    conf_df.head()\n","    conf_elo_dict = {}\n","    for c in confs: conf_elo_dict[c] = []\n","\n","    elo_dict = dict(zip(list(team_ids), [1500] * len(team_ids)))\n","    rs['margin'] = rs.WScore - rs.LScore\n","\n","    preds = []\n","    w_elo = []\n","    l_elo = []\n","\n","    season_conf_elos = []\n","\n","    # Group the DataFrame by 'Season'\n","    grouped = rs.groupby('Season')\n","\n","    # Iterate over each group\n","    for season, group in grouped:\n","\n","        # Iterate over each game in the season\n","        for row in group.itertuples():\n","        \n","            # Get key data from current row\n","            w = row.WTeamID\n","            l = row.LTeamID\n","            margin = row.margin\n","            wloc = row.WLoc\n","            \n","            # Does either team get a home-court advantage?\n","            w_ad, l_ad, = 0., 0.\n","            if wloc == \"H\":\n","                w_ad += HOME_ADVANTAGE\n","            elif wloc == \"A\":\n","                l_ad += HOME_ADVANTAGE\n","            \n","            # Get elo updates as a result of the game\n","            pred, update = elo_update(elo_dict[w] + w_ad,\n","                                    elo_dict[l] + l_ad, \n","                                    margin, K)\n","            elo_dict[w] += update\n","            elo_dict[l] -= update\n","        \n","            # Save prediction and new Elos for each round\n","            preds.append(pred)\n","            w_elo.append(elo_dict[w])\n","            l_elo.append(elo_dict[l])\n","        \n","        # Assigning teams to conference\n","        for id in team_ids:\n","            if f\"{season}_{id}\" in conf_dict.keys(): conf_elo_dict[conf_dict[f\"{season}_{id}\"]].append(elo_dict[id]) # Only updating teams which are active\n","        \n","        # Calculating mean elo by conference\n","        for k, v in conf_elo_dict.items():\n","            if len(v) > 0: conf_elo_dict[k] = [sum(v)/len(v)] # Only modifying conferences with at least one team\n","    \n","        # Reverting each team's elo towards mean\n","        for id in team_ids:\n","            if f\"{season}_{id}\" in conf_dict.keys(): # Only updating teams which are D1\n","                this_conf = conf_dict[f\"{season}_{id}\"]\n","                this_conf_elo = conf_elo_dict[this_conf][0]\n","                elo_dict[id] = (1 - CONF_REGRESSION_FACTOR - D1_REGRESSION_FACTOR) * elo_dict[id] + CONF_REGRESSION_FACTOR * this_conf_elo + D1_REGRESSION_FACTOR * 1500\n","        \n","        # Clearing conference season ave elo ratings\n","        for k in conf_elo_dict.keys():\n","            if len(conf_elo_dict[k]) > 0: \n","                season_conf_elos.append( (season, k, conf_elo_dict[k][0]) )\n","                conf_elo_dict[k] = []\n","\n","    rs['w_elo'] = w_elo\n","    rs['l_elo'] = l_elo\n","\n","    this_log_loss = np.mean(-np.log(preds))\n","    new_tuple = (K, CONF_REGRESSION_FACTOR, D1_REGRESSION_FACTOR, this_log_loss)\n","    PARAM_TUPLES[index] = new_tuple\n","\n","    if (index + 1) % 50 == 0: print(f\"Completed iteration {index+1}\")\n","\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"3c2255a5-661f-4ade-88b1-d5851224afbe","_uuid":"97afdd8f5777b10b7d81b8d998b599e300ffe9bf","trusted":true},"outputs":[],"source":["# Saving the results to a csv file\n","param_df = pd.DataFrame(PARAM_TUPLES, columns=['K', 'CONF_REGRESSION_PARAM', 'D1_REGRESSION_PARAM', 'log_loss'])\n","param_df.to_csv(\"results/k_CONF-REGRESSION-PARAM_D1-REGRESSION-PARAM_results.csv\",index=None)"]},{"cell_type":"markdown","metadata":{},"source":["Now, to analyze the results. I'm going to start by printing out the ten sets of parameters which achieved the best results. I expect that these will be bunched relatively tightly. That is, if (X,Y,Z) is the optimal set of hyper parameters, I'm also expecting to see (X+4,Y,Z), (X-4,Y,Z), (X,Y+.05,Z), etc. among the top sets of hyperparameters. I also want the optimal set of hyperparameters to be near the center of the range. It's okay if D1_REGRESSION_PARAMETER or CONF_REGRESSION_PARAMETER is 0, because that bound is set by the domain; it would be nonsensical to move each team away from the D1 or conference mean elo rating each year. If the optimal hyperparameter is at any of the other bounds, though, this indicates that my bounds aren't optimal."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>K</th>\n","      <th>CONF_REGRESSION_PARAM</th>\n","      <th>D1_REGRESSION_PARAM</th>\n","      <th>log_loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>375</th>\n","      <td>48</td>\n","      <td>0.35</td>\n","      <td>0.0</td>\n","      <td>0.519821</td>\n","    </tr>\n","    <tr>\n","      <th>458</th>\n","      <td>52</td>\n","      <td>0.40</td>\n","      <td>0.0</td>\n","      <td>0.519842</td>\n","    </tr>\n","    <tr>\n","      <th>453</th>\n","      <td>52</td>\n","      <td>0.35</td>\n","      <td>0.0</td>\n","      <td>0.519844</td>\n","    </tr>\n","    <tr>\n","      <th>380</th>\n","      <td>48</td>\n","      <td>0.40</td>\n","      <td>0.0</td>\n","      <td>0.519898</td>\n","    </tr>\n","    <tr>\n","      <th>369</th>\n","      <td>48</td>\n","      <td>0.30</td>\n","      <td>0.0</td>\n","      <td>0.519970</td>\n","    </tr>\n","    <tr>\n","      <th>462</th>\n","      <td>52</td>\n","      <td>0.45</td>\n","      <td>0.0</td>\n","      <td>0.520045</td>\n","    </tr>\n","    <tr>\n","      <th>536</th>\n","      <td>56</td>\n","      <td>0.40</td>\n","      <td>0.0</td>\n","      <td>0.520046</td>\n","    </tr>\n","    <tr>\n","      <th>447</th>\n","      <td>52</td>\n","      <td>0.30</td>\n","      <td>0.0</td>\n","      <td>0.520069</td>\n","    </tr>\n","    <tr>\n","      <th>297</th>\n","      <td>44</td>\n","      <td>0.35</td>\n","      <td>0.0</td>\n","      <td>0.520093</td>\n","    </tr>\n","    <tr>\n","      <th>531</th>\n","      <td>56</td>\n","      <td>0.35</td>\n","      <td>0.0</td>\n","      <td>0.520121</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      K  CONF_REGRESSION_PARAM  D1_REGRESSION_PARAM  log_loss\n","375  48                   0.35                  0.0  0.519821\n","458  52                   0.40                  0.0  0.519842\n","453  52                   0.35                  0.0  0.519844\n","380  48                   0.40                  0.0  0.519898\n","369  48                   0.30                  0.0  0.519970\n","462  52                   0.45                  0.0  0.520045\n","536  56                   0.40                  0.0  0.520046\n","447  52                   0.30                  0.0  0.520069\n","297  44                   0.35                  0.0  0.520093\n","531  56                   0.35                  0.0  0.520121"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Not the most efficient way to achieve these results but a simple way\n","param_df = pd.read_csv(\"results/k_CONF-REGRESSION-PARAM_D1-REGRESSION-PARAM_results.csv\")\n","param_df = param_df.sort_values(by=['log_loss'], ascending=True)\n","param_df.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["This is a clear indicator that the optimal hyper parameters has D1_REGRESSION_FACTOR set to 0, CONF_REGRESSION_FACTOR set at 0.35 or 0.4, and K set at 48 or 52. I'll split the difference and make my optimal hyperparemeter tuples (50, 0.375,0)."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":1}
